{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647e7e58-297e-420f-a244-990d34be7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "import os\n",
    "import wandb\n",
    "import glob\n",
    "import torch\n",
    "import monai\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341556b-3dd8-44bf-9bb6-dc11451afa69",
   "metadata": {},
   "source": [
    "### Set-up transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76bc5bb-b3a6-4808-ac00-c3a291459224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:1 device\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1024)\n",
    "np.random.seed(1024)\n",
    "device = torch.device(\n",
    "    \"cuda:1\"\n",
    "    if torch.cuda.is_available()\n",
    "    else\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.45, ], [0.35, ]),\n",
    "    transforms.Resize([256, 256]),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomResizedCrop([256, 256]),\n",
    "    \n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize([256, 256], interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.RandomRotation(45, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.RandomResizedCrop([256, 256], interpolation=transforms.InterpolationMode.NEAREST)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b9a53-5df7-4dfb-abfa-1339f4810b60",
   "metadata": {},
   "source": [
    "### Init hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97a86af4-4ec3-4f3d-aa69-2870690ffc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-30 21:35:08,235 - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mr-j-poelarends\u001b[0m (\u001b[33mdeeplearning-med\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DL_for_medical_imaging_analysis/Final_Project/wandb/run-20230530_213509-94tr2iff</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deeplearning-med/Training%20Models/runs/94tr2iff' target=\"_blank\">Linknet - Resnet34</a></strong> to <a href='https://wandb.ai/deeplearning-med/Training%20Models' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deeplearning-med/Training%20Models' target=\"_blank\">https://wandb.ai/deeplearning-med/Training%20Models</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deeplearning-med/Training%20Models/runs/94tr2iff' target=\"_blank\">https://wandb.ai/deeplearning-med/Training%20Models/runs/94tr2iff</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 8\n",
    "weight_decay = 1e-5\n",
    "num_epochs = 25\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"Training Models\",\n",
    "    name='Linknet - Resnet34',\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning rate\": lr,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"weight decay\": weight_decay,\n",
    "        \"Epoches number\": num_epochs,\n",
    "        \"transform\": str(transform),\n",
    "        \"target transform\": str(target_transform)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bfe9b4-3b82-46c2-bb40-a7d8a900298d",
   "metadata": {},
   "source": [
    "### Create Segmentation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f99d828-b7b4-47a4-816b-81c3f9411538",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    def __init__(self, data_root, transform, target_transform, train=True):\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train\n",
    "        self.gt_files_path = []\n",
    "        \n",
    "        # find all patient directories\n",
    "        patient_directories = glob.glob(os.path.join(self.data_root, 'patient*'))\n",
    "        # find all files with the suffix _gt.npy\n",
    "        train_size = int(len(patient_directories)*0.8)\n",
    "        \n",
    "        if self.train:\n",
    "            for patient_directory in patient_directories[0:train_size]:\n",
    "                per_patient_file_path = glob.glob(os.path.join(patient_directory, '*_gt.npy'))\n",
    "                for path in per_patient_file_path:\n",
    "                    self.gt_files_path.append(path)\n",
    "        else:\n",
    "            for patient_directory in patient_directories[train_size:]:\n",
    "                per_patient_file_path = glob.glob(os.path.join(patient_directory, '*_gt.npy'))\n",
    "                for path in per_patient_file_path:\n",
    "                    self.gt_files_path.append(path)\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.gt_files_path)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        gt_image_path = self.gt_files_path[index]\n",
    "        image_path = gt_image_path[:-7] + \".npy\"\n",
    "        image = np.load(image_path)\n",
    "        gt_image = np.load(gt_image_path)\n",
    "        image = torch.tensor(image[None,:,:]).float()\n",
    "        gt_image = torch.tensor(gt_image).long()\n",
    "        # Convert the ground truth label to one-hot encoding\n",
    "        one_hot_label = torch.nn.functional.one_hot(gt_image, num_classes=4)\n",
    "\n",
    "        # Transpose the tensor to have dimensions (C, H, W)\n",
    "        one_hot_label = one_hot_label.permute(2, 0, 1)\n",
    "\n",
    "        # Remove the background channel (dimension 0)\n",
    "        one_hot_label = one_hot_label[1:, :, :]\n",
    "        \n",
    "        # Use seed to make sure image and target has same transform\n",
    "        seed = np.random.randint(2147483647)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        target = self.target_transform(one_hot_label)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29be4b64-a02f-4bde-9c06-249d4448f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SegDataset(data_root = './database/training', \n",
    "                     transform = transform, \n",
    "                     target_transform = target_transform,\n",
    "                     train = True)\n",
    "\n",
    "val_dataset = SegDataset(data_root = './database/training', \n",
    "                     transform = transform, \n",
    "                     target_transform = target_transform,\n",
    "                     train = False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a235bf-de5f-412c-bfd0-092df2a89025",
   "metadata": {},
   "source": [
    "### Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1a5c018-ef5a-40e9-b7ac-5e38427fb2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Linknet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels\n",
    "    classes=3,                      # model output channels (number of classes)\n",
    ")\n",
    "\n",
    "#preprocess_input = get_preprocessing_fn('resnet50', pretrained='imagenet')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "seg_loss = monai.losses.DiceCELoss(sigmoid=True, squared_pred=True, reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387bbbbc-97b5-4db4-abfa-f8fafd42cf51",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0650ddcb-f6f0-4ce1-8034-fabceca1e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_img(img, mask):\n",
    "    # img: (B, 256, 64, 64), {: (B, 1, 256, 256)\n",
    "    #print(f\"{img.shape=}, {mask.shape=}\")\n",
    "    img = np.squeeze(img)\n",
    "    mask = np.squeeze(mask)\n",
    "    plt.figure()  \n",
    "    plt.imshow(img, 'gray')\n",
    "    overlay_mask_1 = np.ma.masked_where(mask[0] == 0, img)\n",
    "    overlay_mask_2 = np.ma.masked_where(mask[1] == 0, img)\n",
    "    overlay_mask_3 = np.ma.masked_where(mask[2] == 0, img)\n",
    "    plt.imshow(overlay_mask_1, 'Greens', alpha = 1, interpolation='nearest')\n",
    "    plt.imshow(overlay_mask_2, 'Reds', alpha = 1, interpolation='nearest')\n",
    "    plt.imshow(overlay_mask_3, 'Purples', alpha = 1, interpolation='nearest')\n",
    "    buffer = io.BytesIO()\n",
    "    plt.savefig(buffer, format='jpeg')\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Convert the in-memory buffer to a NumPy array\n",
    "    image_array = np.array(Image.open(buffer))\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4fc692e-4185-46df-9158-750dd1905025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step, (img, gt) in enumerate(tqdm(train_loader)):\n",
    "#     vis_img(img[5][0].numpy(), gt[5])\n",
    "#     break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5459ad7a-ff4e-4f71-81eb-5947426b6672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:37<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Train Loss: 185.93024796247482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Validation Loss: 43.04719823598862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:35<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2, Train Loss: 161.82809907197952\n",
      "EPOCH: 2, Validation Loss: 43.04719823598862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:35<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3, Train Loss: 135.51280772686005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3, Validation Loss: 31.273395657539368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:35<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4, Train Loss: 112.99926188588142\n",
      "EPOCH: 4, Validation Loss: 31.273395657539368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:37<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5, Train Loss: 96.6851849257946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:04<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5, Validation Loss: 20.191386118531227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:36<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 6, Train Loss: 83.74024805426598\n",
      "EPOCH: 6, Validation Loss: 20.191386118531227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:36<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 7, Train Loss: 77.46669572591782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:06<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 7, Validation Loss: 17.228460729122162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:39<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 8, Train Loss: 74.92693395912647\n",
      "EPOCH: 8, Validation Loss: 17.228460729122162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:38<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 9, Train Loss: 70.60948587954044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 9, Validation Loss: 16.220476284623146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:38<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10, Train Loss: 68.89738744497299\n",
      "EPOCH: 10, Validation Loss: 16.220476284623146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:35<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11, Train Loss: 64.48595505952835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 11, Validation Loss: 15.231720834970474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:36<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 12, Train Loss: 60.88318522274494\n",
      "EPOCH: 12, Validation Loss: 15.231720834970474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:37<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13, Train Loss: 59.29736603796482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 13, Validation Loss: 14.834540486335754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:38<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 14, Train Loss: 58.620212972164154\n",
      "EPOCH: 14, Validation Loss: 14.834540486335754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:42<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15, Train Loss: 60.054640263319016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15, Validation Loss: 12.706520937383175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:42<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 16, Train Loss: 56.14017079770565\n",
      "EPOCH: 16, Validation Loss: 12.706520937383175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:38<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17, Train Loss: 55.69070006161928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 17, Validation Loss: 12.148647278547287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:43<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 18, Train Loss: 55.577513709664345\n",
      "EPOCH: 18, Validation Loss: 12.148647278547287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:38<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19, Train Loss: 52.68721070885658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 19, Validation Loss: 12.954071432352066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:39<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20, Train Loss: 51.00518652796745\n",
      "EPOCH: 20, Validation Loss: 12.954071432352066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:37<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 21, Train Loss: 52.13398556411266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:09<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 21, Validation Loss: 12.855387702584267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:41<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 22, Train Loss: 51.56878016144037\n",
      "EPOCH: 22, Validation Loss: 12.855387702584267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:39<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 23, Train Loss: 53.94743222743273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 23, Validation Loss: 12.873438894748688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:41<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 24, Train Loss: 49.926273591816425\n",
      "EPOCH: 24, Validation Loss: 12.873438894748688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:38<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 25, Train Loss: 51.95261249691248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:05<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 25, Validation Loss: 12.662543073296547\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "best_loss = 1e10\n",
    "val_freq = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for step, (img, gt) in enumerate(tqdm(train_loader)):\n",
    "        img = img.to(device)\n",
    "        mask = model(img)\n",
    "        loss = seg_loss(mask, gt.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f'EPOCH: {epoch + 1}, Train Loss: {epoch_loss}')\n",
    "    \n",
    "    # Validation\n",
    "    if epoch % val_freq == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        last_image_batch = None\n",
    "        last_gt_mask_batch = None\n",
    "        last_pr_mask_batch = None\n",
    "        with torch.no_grad():\n",
    "            for step, (img, gt) in enumerate(tqdm(val_loader)):\n",
    "                img = img.to(device)\n",
    "                mask = model(img)\n",
    "                loss = seg_loss(mask, gt.to(device))\n",
    "                val_loss += loss.item()\n",
    "                last_image_batch = img\n",
    "                last_gt_mask_batch = gt\n",
    "                last_pr_mask_batch = mask\n",
    "            \n",
    "    print(f'EPOCH: {epoch + 1}, Validation Loss: {val_loss}')\n",
    "    \n",
    "    last_image = last_image_batch.detach().cpu().numpy()[0][0]\n",
    "    last_gt = last_gt_mask_batch.detach().cpu().numpy()[0]\n",
    "    last_pr = last_pr_mask_batch.detach().cpu().numpy()[0]\n",
    "    \n",
    "    threshold = 0.95  # Set your desired threshold value\n",
    "    binary_mask = (last_pr > threshold)\n",
    "    \n",
    "    ground_truth = vis_img(last_image, last_gt)\n",
    "    predicted = vis_img(last_image, binary_mask)\n",
    "    # Log\n",
    "    wandb.log({\"loss\": epoch_loss,\n",
    "               \"val_loss\": val_loss,\n",
    "               \"ground_truth\": wandb.Image(ground_truth),\n",
    "               \"prediction\": wandb.Image(predicted)})\n",
    "    \n",
    "    # save the best model\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), './model/linknet-resnet34/model_best.pth')\n",
    "torch.save(model.state_dict(), './model/linknet-resnet34/model_final_epoch.pth')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63789c44-1387-4b22-ba17-14ee9b50b7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
