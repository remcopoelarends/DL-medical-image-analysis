{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71de4d6e-407e-464b-9dfd-08b741cded75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: medpy in /home/jovyan/.local/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/jovyan/.local/lib/python3.8/site-packages (from medpy) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from medpy) (1.23.1)\n",
      "Requirement already satisfied: SimpleITK>=1.1.0 in /home/jovyan/.local/lib/python3.8/site-packages (from medpy) (2.2.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nibabel\n",
      "  Downloading nibabel-5.1.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources>=1.3 in /usr/local/lib/python3.8/dist-packages (from nibabel) (5.12.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from nibabel) (1.23.1)\n",
      "Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.8/dist-packages (from nibabel) (23.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.3->nibabel) (3.15.0)\n",
      "Installing collected packages: nibabel\n",
      "\u001b[33m  WARNING: The scripts nib-conform, nib-convert, nib-dicomfs, nib-diff, nib-ls, nib-nifti-dx, nib-roi, nib-stats, nib-tck2trk, nib-trk2tck and parrec2nii are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed nibabel-5.1.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install medpy\n",
    "# !pip install nibabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7dd5a-6ddb-49a9-9c48-2f133b31046b",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "Filename is Timestamp related. Run from start everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0cf677-9488-4432-9823-2e99c5d93ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import time\n",
    "import re\n",
    "import argparse\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from medpy.metric.binary import hd, dc, jc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "HEADER = [\"Name\", \"Dice LV\", \"Volume LV\", \"Err LV(ml)\", \"Hausdorff LV\", \"Jaccard LV\",\n",
    "          \"Dice RV\", \"Volume RV\", \"Err RV(ml)\", \"Hausdorff RV\", \"Jaccard RV\",\n",
    "          \"Dice MYO\", \"Volume MYO\", \"Err MYO(ml)\", \"Hausdorff MYO\", \"Jaccard MYO\"]\n",
    "\n",
    "csv_path = \"results_{}.csv\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "#\n",
    "# Utils functions used to sort strings into a natural order\n",
    "#\n",
    "def conv_int(i):\n",
    "    return int(i) if i.isdigit() else i\n",
    "\n",
    "\n",
    "def natural_order(sord):\n",
    "    \"\"\"\n",
    "    Sort a (list,tuple) of strings into natural order.\n",
    "\n",
    "    Ex:\n",
    "\n",
    "    ['1','10','2'] -> ['1','2','10']\n",
    "\n",
    "    ['abc1def','ab10d','b2c','ab1d'] -> ['ab1d','ab10d', 'abc1def', 'b2c']\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(sord, tuple):\n",
    "        sord = sord[0]\n",
    "    return [conv_int(c) for c in re.split(r'(\\d+)', sord)]\n",
    "\n",
    "\n",
    "def load_nii(img_path):\n",
    "    \"\"\"\n",
    "    Function to load a 'nii' or 'nii.gz' file, The function returns\n",
    "    everything needed to save another 'nii' or 'nii.gz'\n",
    "    in the same dimensional space, i.e. the affine matrix and the header\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    img_path: string\n",
    "    String with the path of the 'nii' or 'nii.gz' image file name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Three element, the first is a numpy array of the image values,\n",
    "    the second is the affine transformation of the image, and the\n",
    "    last one is the header of the image.\n",
    "    \"\"\"\n",
    "    nimg = nib.load(img_path)\n",
    "    return np.asanyarray(nimg.dataobj), nimg.affine, nimg.header\n",
    "\n",
    "\n",
    "def save_nii(img_path, data, affine, header):\n",
    "    \"\"\"\n",
    "    Function to save a 'nii' or 'nii.gz' file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    img_path: string\n",
    "    Path to save the image should be ending with '.nii' or '.nii.gz'.\n",
    "\n",
    "    data: np.array\n",
    "    Numpy array of the image data.\n",
    "\n",
    "    affine: list of list or np.array\n",
    "    The affine transformation to save with the image.\n",
    "\n",
    "    header: nib.Nifti1Header\n",
    "    The header that define everything about the data\n",
    "    (pleasecheck nibabel documentation).\n",
    "    \"\"\"\n",
    "    nimg = nib.Nifti1Image(data, affine=affine, header=header)\n",
    "    nimg.to_filename(img_path)\n",
    "\n",
    "\n",
    "#\n",
    "# Functions to process files, directories and metrics\n",
    "#\n",
    "def metrics(img_gt, img_pred, voxel_size):\n",
    "    \"\"\"\n",
    "    Function to compute the metrics between two segmentation maps given as input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_gt: np.array\n",
    "    Array of the ground truth segmentation map.\n",
    "\n",
    "    img_pred: np.array\n",
    "    Array of the predicted segmentation map.\n",
    "\n",
    "    voxel_size: list, tuple or np.array\n",
    "    The size of a voxel of the images used to compute the volumes.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A list of metrics in this order, [Dice LV, Volume LV, Err LV(ml),\n",
    "    Dice RV, Volume RV, Err RV(ml), Dice MYO, Volume MYO, Err MYO(ml)]\n",
    "    \"\"\"\n",
    "\n",
    "    if img_gt.ndim != img_pred.ndim:\n",
    "        raise ValueError(\"The arrays 'img_gt' and 'img_pred' should have the \"\n",
    "                         \"same dimension, {} against {}\".format(img_gt.ndim,\n",
    "                                                                img_pred.ndim))\n",
    "\n",
    "    res = []\n",
    "    # Loop on each classes of the input images\n",
    "    for c in [3, 1, 2]:\n",
    "        # Copy the gt image to not alterate the input\n",
    "        gt_c_i = np.copy(img_gt)\n",
    "        gt_c_i[gt_c_i != c] = 0\n",
    "\n",
    "        # Copy the pred image to not alterate the input\n",
    "        pred_c_i = np.copy(img_pred)\n",
    "        pred_c_i[pred_c_i != c] = 0\n",
    "\n",
    "        # Clip the value to compute the volumes\n",
    "        gt_c_i = np.clip(gt_c_i, 0, 1)\n",
    "        pred_c_i = np.clip(pred_c_i, 0, 1)\n",
    "\n",
    "        # Compute the Dice\n",
    "        dice = dc(gt_c_i, pred_c_i)\n",
    "\n",
    "        # Compute volume\n",
    "        volpred = pred_c_i.sum() * np.prod(voxel_size) / 1000.\n",
    "        volgt = gt_c_i.sum() * np.prod(voxel_size) / 1000.\n",
    "\n",
    "        hausdorff = hd(gt_c_i, pred_c_i)\n",
    "        \n",
    "        jaccard = jc(gt_c_i, pred_c_i)\n",
    "        \n",
    "        res += [dice, volpred, volpred-volgt, hausdorff, jaccard]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_metrics_on_files(path_gt, path_pred):\n",
    "    \"\"\"\n",
    "    Function to give the metrics for two files\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    path_gt: string\n",
    "    Path of the ground truth image.\n",
    "\n",
    "    path_pred: string\n",
    "    Path of the predicted image.\n",
    "    \"\"\"\n",
    "    gt, _, header = load_nii(path_gt)\n",
    "    pred, _, _ = load_nii(path_pred)\n",
    "    zooms = header.get_zooms()\n",
    "\n",
    "    name = os.path.basename(path_gt)\n",
    "    name = name.split('.')[0]\n",
    "    res = metrics(gt, pred, zooms)\n",
    "    res = [\"{:.3f}\".format(r) for r in res]\n",
    "\n",
    "    formatting = \"{:>14}, {:>7}, {:>9}, {:>10}, {:>7}, {:>9}, {:>10}, {:>8}, {:>10}, {:>11}, {:>11}, {:>11}, {:>11}, {:>11}, {:>11}, {:>11}\"\n",
    "    print(formatting.format(*HEADER))\n",
    "    print(formatting.format(name, *res))\n",
    "\n",
    "\n",
    "def compute_metrics_on_directories(dir_gt, dir_pred):\n",
    "    \"\"\"\n",
    "    Function to generate a csv file for each images of two directories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    path_gt: string\n",
    "    Directory of the ground truth segmentation maps.\n",
    "\n",
    "    path_pred: string\n",
    "    Directory of the predicted segmentation maps.\n",
    "    \"\"\"\n",
    "    lst_gt = sorted(glob(os.path.join(dir_gt, '*')), key=natural_order)\n",
    "    lst_pred = sorted(glob(os.path.join(dir_pred, '*')), key=natural_order)\n",
    "\n",
    "    res = []\n",
    "    for p_gt, p_pred in zip(lst_gt, lst_pred):\n",
    "        if os.path.basename(p_gt) != os.path.basename(p_pred):\n",
    "            raise ValueError(\"The two files don't have the same name\"\n",
    "                             \" {}, {}.\".format(os.path.basename(p_gt),\n",
    "                                               os.path.basename(p_pred)))\n",
    "\n",
    "        gt, _, header = load_nii(p_gt)\n",
    "        pred, _, _ = load_nii(p_pred)\n",
    "        zooms = header.get_zooms()\n",
    "        res.append(metrics(gt, pred, zooms))\n",
    "\n",
    "    lst_name_gt = [os.path.basename(gt).split(\".\")[0] for gt in lst_gt]\n",
    "    res = [[n,] + r for r, n in zip(res, lst_name_gt)]\n",
    "    df = pd.DataFrame(res, columns=HEADER)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "def get_result(path_gt, path_pred):\n",
    "    \"\"\"\n",
    "    Main function to select which method to apply on the input parameters.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(path_gt) and os.path.isfile(path_pred):\n",
    "        compute_metrics_on_files(path_gt, path_pred)\n",
    "    elif os.path.isdir(path_gt) and os.path.isdir(path_pred):\n",
    "        compute_metrics_on_directories(path_gt, path_pred)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"The paths given needs to be two directories or two files.\")\n",
    "\n",
    "model_name = \"FINAL\"\n",
    "gt_img_path = 'predictions/'+model_name+'/gt'\n",
    "pred_img_path = 'predictions/'+model_name+'/pred'\n",
    "get_result(gt_img_path, pred_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df854944-ae32-4d24-8dc8-4593f814cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice LV            0.898463\n",
      "Volume LV        135.484213\n",
      "Err LV(ml)        -2.104567\n",
      "Hausdorff LV      16.246707\n",
      "Jaccard LV         0.824192\n",
      "Dice RV            0.833097\n",
      "Volume RV        151.069903\n",
      "Err RV(ml)        18.209512\n",
      "Hausdorff RV      46.849893\n",
      "Jaccard RV         0.722915\n",
      "Dice MYO           0.830161\n",
      "Volume MYO       133.996273\n",
      "Err MYO(ml)        0.925755\n",
      "Hausdorff MYO     17.736726\n",
      "Jaccard MYO        0.711853\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(df)\n",
    "\n",
    "# Calculate the mean of each column (except the \"Name\" column)\n",
    "mean_values = df.iloc[:, 1:].mean()\n",
    "\n",
    "# Display the mean values\n",
    "print(mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa1682-61ad-4d1d-a31a-e64900baf993",
   "metadata": {},
   "source": [
    "## Place in WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c95be451-0785-402b-9e1a-c2e8af2add95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mr-j-poelarends\u001b[0m (\u001b[33mdeeplearning-med\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c71c2d1ebd540eabe459e5622e50871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669096432936688, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DL_for_medical_imaging_analysis/Final_Project/wandb/run-20230619_141505-k8cl85k4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deeplearning-med/Official%20Evaluation/runs/k8cl85k4' target=\"_blank\">FINAL</a></strong> to <a href='https://wandb.ai/deeplearning-med/Official%20Evaluation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deeplearning-med/Official%20Evaluation' target=\"_blank\">https://wandb.ai/deeplearning-med/Official%20Evaluation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deeplearning-med/Official%20Evaluation/runs/k8cl85k4' target=\"_blank\">https://wandb.ai/deeplearning-med/Official%20Evaluation/runs/k8cl85k4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init(\n",
    "    project=\"Official Evaluation\",\n",
    "    name=model_name,\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"Model\": model_name\n",
    "    })\n",
    "\n",
    "wandb.log({\"Dice LV\": mean_values[0],\n",
    "          \"Volume LV\": mean_values[1], \n",
    "          \"Err LV (ml)\": mean_values[2],\n",
    "          \"Hausdorff RV\": mean_values[3],\n",
    "          \"Jaccard RV\": mean_values[4],\n",
    "          \"Dice RV\": mean_values[5], \n",
    "          \"Volume RV\": mean_values[6], \n",
    "          \"Err RV(ml)\": mean_values[7], \n",
    "          \"Hausdorff LV\": mean_values[8],\n",
    "          \"Jaccard LV\": mean_values[9],\n",
    "           \"Dice MYO\": mean_values[10], \n",
    "          \"Volume MYO\": mean_values[11], \n",
    "          \"Err MYO(ml)\": mean_values[12], \n",
    "          \"Hausdorff MYO\": mean_values[13],\n",
    "          \"Jaccard MYO\": mean_values[14],\n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df98d835-c38f-4235-bf7b-4df119e842d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
