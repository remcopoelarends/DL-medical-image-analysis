{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71de4d6e-407e-464b-9dfd-08b741cded75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: medpy in /home/jovyan/.local/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from medpy) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from medpy) (1.23.1)\n",
      "Requirement already satisfied: SimpleITK>=1.1.0 in /home/jovyan/.local/lib/python3.8/site-packages (from medpy) (2.2.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nibabel in /home/jovyan/.local/lib/python3.8/site-packages (5.1.0)\n",
      "Requirement already satisfied: importlib-resources>=1.3 in /usr/local/lib/python3.8/dist-packages (from nibabel) (5.12.0)\n",
      "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.8/dist-packages (from nibabel) (1.23.1)\n",
      "Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.8/dist-packages (from nibabel) (23.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.3->nibabel) (3.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install medpy\n",
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7dd5a-6ddb-49a9-9c48-2f133b31046b",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "Filename is Timestamp related. Run from start everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0cf677-9488-4432-9823-2e99c5d93ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import time\n",
    "import re\n",
    "import argparse\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from medpy.metric.binary import hd, dc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "HEADER = [\"Name\", \"Dice LV\", \"Volume LV\", \"Err LV(ml)\",\n",
    "          \"Dice RV\", \"Volume RV\", \"Err RV(ml)\",\n",
    "          \"Dice MYO\", \"Volume MYO\", \"Err MYO(ml)\"]\n",
    "\n",
    "csv_path = \"results_{}.csv\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "#\n",
    "# Utils functions used to sort strings into a natural order\n",
    "#\n",
    "def conv_int(i):\n",
    "    return int(i) if i.isdigit() else i\n",
    "\n",
    "\n",
    "def natural_order(sord):\n",
    "    \"\"\"\n",
    "    Sort a (list,tuple) of strings into natural order.\n",
    "\n",
    "    Ex:\n",
    "\n",
    "    ['1','10','2'] -> ['1','2','10']\n",
    "\n",
    "    ['abc1def','ab10d','b2c','ab1d'] -> ['ab1d','ab10d', 'abc1def', 'b2c']\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(sord, tuple):\n",
    "        sord = sord[0]\n",
    "    return [conv_int(c) for c in re.split(r'(\\d+)', sord)]\n",
    "\n",
    "\n",
    "def load_nii(img_path):\n",
    "    \"\"\"\n",
    "    Function to load a 'nii' or 'nii.gz' file, The function returns\n",
    "    everything needed to save another 'nii' or 'nii.gz'\n",
    "    in the same dimensional space, i.e. the affine matrix and the header\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    img_path: string\n",
    "    String with the path of the 'nii' or 'nii.gz' image file name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Three element, the first is a numpy array of the image values,\n",
    "    the second is the affine transformation of the image, and the\n",
    "    last one is the header of the image.\n",
    "    \"\"\"\n",
    "    nimg = nib.load(img_path)\n",
    "    return np.asanyarray(nimg.dataobj), nimg.affine, nimg.header\n",
    "\n",
    "\n",
    "def save_nii(img_path, data, affine, header):\n",
    "    \"\"\"\n",
    "    Function to save a 'nii' or 'nii.gz' file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    img_path: string\n",
    "    Path to save the image should be ending with '.nii' or '.nii.gz'.\n",
    "\n",
    "    data: np.array\n",
    "    Numpy array of the image data.\n",
    "\n",
    "    affine: list of list or np.array\n",
    "    The affine transformation to save with the image.\n",
    "\n",
    "    header: nib.Nifti1Header\n",
    "    The header that define everything about the data\n",
    "    (pleasecheck nibabel documentation).\n",
    "    \"\"\"\n",
    "    nimg = nib.Nifti1Image(data, affine=affine, header=header)\n",
    "    nimg.to_filename(img_path)\n",
    "\n",
    "\n",
    "#\n",
    "# Functions to process files, directories and metrics\n",
    "#\n",
    "def metrics(img_gt, img_pred, voxel_size):\n",
    "    \"\"\"\n",
    "    Function to compute the metrics between two segmentation maps given as input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_gt: np.array\n",
    "    Array of the ground truth segmentation map.\n",
    "\n",
    "    img_pred: np.array\n",
    "    Array of the predicted segmentation map.\n",
    "\n",
    "    voxel_size: list, tuple or np.array\n",
    "    The size of a voxel of the images used to compute the volumes.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    A list of metrics in this order, [Dice LV, Volume LV, Err LV(ml),\n",
    "    Dice RV, Volume RV, Err RV(ml), Dice MYO, Volume MYO, Err MYO(ml)]\n",
    "    \"\"\"\n",
    "\n",
    "    if img_gt.ndim != img_pred.ndim:\n",
    "        raise ValueError(\"The arrays 'img_gt' and 'img_pred' should have the \"\n",
    "                         \"same dimension, {} against {}\".format(img_gt.ndim,\n",
    "                                                                img_pred.ndim))\n",
    "\n",
    "    res = []\n",
    "    # Loop on each classes of the input images\n",
    "    for c in [3, 1, 2]:\n",
    "        # Copy the gt image to not alterate the input\n",
    "        gt_c_i = np.copy(img_gt)\n",
    "        gt_c_i[gt_c_i != c] = 0\n",
    "\n",
    "        # Copy the pred image to not alterate the input\n",
    "        pred_c_i = np.copy(img_pred)\n",
    "        pred_c_i[pred_c_i != c] = 0\n",
    "\n",
    "        # Clip the value to compute the volumes\n",
    "        gt_c_i = np.clip(gt_c_i, 0, 1)\n",
    "        pred_c_i = np.clip(pred_c_i, 0, 1)\n",
    "\n",
    "        # Compute the Dice\n",
    "        dice = dc(gt_c_i, pred_c_i)\n",
    "\n",
    "        # Compute volume\n",
    "        volpred = pred_c_i.sum() * np.prod(voxel_size) / 1000.\n",
    "        volgt = gt_c_i.sum() * np.prod(voxel_size) / 1000.\n",
    "\n",
    "        res += [dice, volpred, volpred-volgt]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_metrics_on_files(path_gt, path_pred):\n",
    "    \"\"\"\n",
    "    Function to give the metrics for two files\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    path_gt: string\n",
    "    Path of the ground truth image.\n",
    "\n",
    "    path_pred: string\n",
    "    Path of the predicted image.\n",
    "    \"\"\"\n",
    "    gt, _, header = load_nii(path_gt)\n",
    "    pred, _, _ = load_nii(path_pred)\n",
    "    zooms = header.get_zooms()\n",
    "\n",
    "    name = os.path.basename(path_gt)\n",
    "    name = name.split('.')[0]\n",
    "    res = metrics(gt, pred, zooms)\n",
    "    res = [\"{:.3f}\".format(r) for r in res]\n",
    "\n",
    "    formatting = \"{:>14}, {:>7}, {:>9}, {:>10}, {:>7}, {:>9}, {:>10}, {:>8}, {:>10}, {:>11}\"\n",
    "    print(formatting.format(*HEADER))\n",
    "    print(formatting.format(name, *res))\n",
    "\n",
    "\n",
    "def compute_metrics_on_directories(dir_gt, dir_pred):\n",
    "    \"\"\"\n",
    "    Function to generate a csv file for each images of two directories.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    path_gt: string\n",
    "    Directory of the ground truth segmentation maps.\n",
    "\n",
    "    path_pred: string\n",
    "    Directory of the predicted segmentation maps.\n",
    "    \"\"\"\n",
    "    lst_gt = sorted(glob(os.path.join(dir_gt, '*')), key=natural_order)\n",
    "    lst_pred = sorted(glob(os.path.join(dir_pred, '*')), key=natural_order)\n",
    "\n",
    "    res = []\n",
    "    for p_gt, p_pred in zip(lst_gt, lst_pred):\n",
    "        if os.path.basename(p_gt) != os.path.basename(p_pred):\n",
    "            raise ValueError(\"The two files don't have the same name\"\n",
    "                             \" {}, {}.\".format(os.path.basename(p_gt),\n",
    "                                               os.path.basename(p_pred)))\n",
    "\n",
    "        gt, _, header = load_nii(p_gt)\n",
    "        pred, _, _ = load_nii(p_pred)\n",
    "        zooms = header.get_zooms()\n",
    "        res.append(metrics(gt, pred, zooms))\n",
    "\n",
    "    lst_name_gt = [os.path.basename(gt).split(\".\")[0] for gt in lst_gt]\n",
    "    res = [[n,] + r for r, n in zip(res, lst_name_gt)]\n",
    "    df = pd.DataFrame(res, columns=HEADER)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "def get_result(path_gt, path_pred):\n",
    "    \"\"\"\n",
    "    Main function to select which method to apply on the input parameters.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(path_gt) and os.path.isfile(path_pred):\n",
    "        compute_metrics_on_files(path_gt, path_pred)\n",
    "    elif os.path.isdir(path_gt) and os.path.isdir(path_pred):\n",
    "        compute_metrics_on_directories(path_gt, path_pred)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"The paths given needs to be two directories or two files.\")\n",
    "gt_img_path = 'prediction/test-gt-unet-res50-vanilla'\n",
    "pred_img_path = 'prediction/test-pred-unet-res50-vanilla'\n",
    "get_result(gt_img_path, pred_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df854944-ae32-4d24-8dc8-4593f814cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Name   Dice LV   Volume LV  Err LV(ml)   Dice RV   \n",
      "0   patient101_frame01_gt  0.946754  206.582909  -16.015222  0.814618  \\\n",
      "1   patient101_frame14_gt  0.907503  155.361114   -0.645992  0.634808   \n",
      "2   patient102_frame01_gt  0.932064   71.850586   -7.592773  0.920175   \n",
      "3   patient102_frame13_gt  0.765891   24.096680    0.952148  0.780094   \n",
      "4   patient103_frame01_gt  0.953539  169.165039   -9.008789  0.819621   \n",
      "..                    ...       ...         ...         ...       ...   \n",
      "95  patient148_frame10_gt  0.900924   86.857398  -14.652504  0.877179   \n",
      "96  patient149_frame01_gt  0.961772  202.500000   -9.353760  0.905002   \n",
      "97  patient149_frame12_gt  0.926453  124.861816    1.008545  0.691501   \n",
      "98  patient150_frame01_gt  0.951696  110.862758   -6.972148  0.912858   \n",
      "99  patient150_frame12_gt  0.780758   34.337361    4.560869  0.756518   \n",
      "\n",
      "     Volume RV  Err RV(ml)  Dice MYO  Volume MYO  Err MYO(ml)  \n",
      "0   133.881875    4.091284  0.783079  126.291467    -1.291984  \n",
      "1    88.770089   18.706856  0.785210  130.355834     1.561148  \n",
      "2   100.537109    0.439453  0.837593   80.664062     7.543945  \n",
      "3    64.990234   15.185547  0.839479   95.654297    11.230469  \n",
      "4    99.243164   10.351562  0.885030  181.933594     8.178711  \n",
      "..         ...         ...       ...         ...          ...  \n",
      "95   95.472629   19.081306  0.841866  111.777671     0.198305  \n",
      "96  205.268555   13.981201  0.852574  137.518066    10.382080  \n",
      "97  145.981934   59.978760  0.845022  152.586914    20.368652  \n",
      "98  111.909514   -3.551496  0.837999   82.506864     2.093514  \n",
      "99   82.058254   28.617583  0.852785   99.068052     0.822452  \n",
      "\n",
      "[100 rows x 10 columns]\n",
      "Dice LV          0.896336\n",
      "Volume LV      133.158053\n",
      "Err LV(ml)      -4.430727\n",
      "Dice RV          0.794956\n",
      "Volume RV      155.801124\n",
      "Err RV(ml)      22.940733\n",
      "Dice MYO         0.822447\n",
      "Volume MYO     144.740395\n",
      "Err MYO(ml)     11.669877\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Calculate the mean of each column (except the \"Name\" column)\n",
    "mean_values = df.iloc[:, 1:].mean()\n",
    "\n",
    "# Display the mean values\n",
    "print(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212ad7f-9e64-4c6b-b316-053888004691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
