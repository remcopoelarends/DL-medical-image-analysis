{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32858f7c-7a23-4503-88f0-a4100a5ba41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import optuna\n",
    "from PIL import Image\n",
    "import os\n",
    "import wandb\n",
    "import glob\n",
    "import torch\n",
    "import monai\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a8ed05-fb81-4038-a4f4-59748002c3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:1 device\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1024)\n",
    "np.random.seed(1024)\n",
    "device = torch.device(\n",
    "    \"cuda:1\"\n",
    "    if torch.cuda.is_available()\n",
    "    else\n",
    "    \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.45, ], [0.35, ]),\n",
    "    transforms.Resize([256, 256]),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomResizedCrop([256, 256])\n",
    "])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize([256, 256], interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.RandomRotation(45, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.RandomResizedCrop([256, 256], interpolation=transforms.InterpolationMode.NEAREST)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7494ecc2-b4ae-4004-bb9d-c0460f9f39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    def __init__(self, data_root, transform, target_transform, train=True, to3d=False):\n",
    "        self.data_root = data_root\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train\n",
    "        self.to3d = to3d\n",
    "        self.gt_files_path = []\n",
    "\n",
    "        # find all patient directories\n",
    "        patient_directories = glob.glob(os.path.join(self.data_root, 'patient*'))\n",
    "        # find all files with the suffix _gt.npy\n",
    "        train_size = int(len(patient_directories)*0.8)\n",
    "\n",
    "        if self.train:\n",
    "            for patient_directory in patient_directories[0:train_size]:\n",
    "                per_patient_file_path = glob.glob(\n",
    "                    os.path.join(patient_directory, '*_gt.npy'))\n",
    "                for path in per_patient_file_path:\n",
    "                    self.gt_files_path.append(path)\n",
    "        else:\n",
    "            for patient_directory in patient_directories[train_size:]:\n",
    "                per_patient_file_path = glob.glob(os.path.join(\n",
    "                    patient_directory, '*_gt.npy'))\n",
    "                for path in per_patient_file_path:\n",
    "                    self.gt_files_path.append(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gt_files_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        gt_image_path = self.gt_files_path[index]\n",
    "        image_path = gt_image_path[:-7] + \".npy\"\n",
    "        image = np.load(image_path)\n",
    "        gt_image = np.load(gt_image_path)\n",
    "        image = torch.tensor(image[None, :, :]).float()\n",
    "        gt_image = torch.tensor(gt_image).long()\n",
    "        # Convert the ground truth label to one-hot encoding\n",
    "        one_hot_label = torch.nn.functional.one_hot(gt_image, num_classes=4)\n",
    "\n",
    "        # Transpose the tensor to have dimensions (C, H, W)\n",
    "        one_hot_label = one_hot_label.permute(2, 0, 1)\n",
    "\n",
    "        # Remove the background channel (dimension 0)\n",
    "        one_hot_label = one_hot_label[1:, :, :]\n",
    "\n",
    "        # Use seed to make sure image and target has same transform\n",
    "        seed = np.random.randint(2147483647)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        target = self.target_transform(one_hot_label)\n",
    "\n",
    "        # Convert 1d grayscale image to 3d, for transformer backbone\n",
    "        if self.to3d:\n",
    "            rgb_tensor = image.repeat(3, 1, 1)\n",
    "            return rgb_tensor, target\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4720964e-c7a4-4e6a-bf1a-776d76c01775",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SegDataset(data_root='./database/training',\n",
    "                           transform=transform,\n",
    "                           target_transform=target_transform,\n",
    "                           train=True,\n",
    "                           to3d=False)\n",
    "\n",
    "val_dataset = SegDataset(data_root='./database/training',\n",
    "                         transform=transform,\n",
    "                         target_transform=target_transform,\n",
    "                         train=False,\n",
    "                         to3d=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52dcbd8-2438-486f-9217-2498e0e66c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_img(img, mask):\n",
    "    img = np.squeeze(img)\n",
    "    mask = np.squeeze(mask)\n",
    "    plt.figure()\n",
    "    plt.imshow(img, 'gray')\n",
    "    overlay_mask_1 = np.ma.masked_where(mask[0] == 0, img)\n",
    "    overlay_mask_2 = np.ma.masked_where(mask[1] == 0, img)\n",
    "    overlay_mask_3 = np.ma.masked_where(mask[2] == 0, img)\n",
    "    plt.imshow(overlay_mask_1, 'Greens', alpha=1, interpolation='nearest')\n",
    "    plt.imshow(overlay_mask_2, 'Reds', alpha=1, interpolation='nearest')\n",
    "    plt.imshow(overlay_mask_3, 'Purples', alpha=1, interpolation='nearest')\n",
    "    buffer = io.BytesIO()\n",
    "    plt.savefig(buffer, format='jpeg')\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Convert the in-memory buffer to a NumPy array\n",
    "    image_array = np.array(Image.open(buffer))\n",
    "    plt.close()\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e138255-68b0-4ab0-b02d-db7369c915ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trial):\n",
    "\n",
    "    # Hyperparameters to be optimized\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    batch_size = 16\n",
    "    weight_decay = trial.suggest_categorical(\"weight_decay\", [1e-4, 1e-5])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "    loss_func = trial.suggest_categorical(\"loss_func\",\n",
    "                                          [\"DiceLoss\",\n",
    "                                           \"GeneralizedDiceLoss\",\n",
    "                                           \"TverskyLoss\"])\n",
    "\n",
    "    # Choose loss function\n",
    "    if loss_func == \"DiceLoss\":\n",
    "        seg_loss = monai.losses.DiceLoss(sigmoid=True,\n",
    "                                         squared_pred=True,\n",
    "                                         reduction='mean')\n",
    "    elif loss_func == \"GeneralizedDiceLoss\":\n",
    "        seg_loss = monai.losses.GeneralizedDiceLoss(sigmoid=True,\n",
    "                                                    squared_pred=True,\n",
    "                                                    reduction='mean')\n",
    "    elif loss_func == \"TverskyLoss\":\n",
    "        seg_loss = monai.losses.TverskyLoss(sigmoid=True,\n",
    "                                            squared_pred=True,\n",
    "                                            reduction='mean')\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=\"Unet-Res50-Tune\",\n",
    "        name=f'Unet-Res50-trial-{trial.number}',\n",
    "        config={\n",
    "            \"number of epoches\": 30,\n",
    "            \"learning rate\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"optimizer\": optimizer_name,\n",
    "            \"weight decay\": weight_decay,\n",
    "            \"loss function\": loss_func,\n",
    "            \"transform\": str(transform),\n",
    "            \"target transform\": str(target_transform)\n",
    "        })\n",
    "\n",
    "    # Set up DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Set up model and optimizer\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet50\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=1,\n",
    "        classes=3\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                     lr=lr,\n",
    "                                     weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                    lr=lr,\n",
    "                                    weight_decay=weight_decay)\n",
    "\n",
    "    best_loss = 1e10\n",
    "    # Start training and validation\n",
    "    for epoch in range(30):\n",
    "        # Train\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for step, (img, gt) in enumerate(tqdm(train_loader)):\n",
    "            img = img.to(device)\n",
    "            mask = model(img)\n",
    "            loss = seg_loss(mask, gt.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f'EPOCH: {epoch + 1}, Train Loss: {epoch_loss}')\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        last_image_batch = None\n",
    "        last_gt_mask_batch = None\n",
    "        last_pr_mask_batch = None\n",
    "        with torch.no_grad():\n",
    "            for step, (img, gt) in enumerate(tqdm(val_loader)):\n",
    "                img = img.to(device)\n",
    "                mask = model(img)\n",
    "                loss = seg_loss(mask, gt.to(device))\n",
    "                val_loss += loss.item()\n",
    "                last_image_batch = img\n",
    "                last_gt_mask_batch = gt\n",
    "                last_pr_mask_batch = mask\n",
    "\n",
    "        print(f'EPOCH: {epoch + 1}, Validation Loss: {val_loss}')\n",
    "\n",
    "        last_image = last_image_batch.detach().cpu().numpy()[0][0]\n",
    "        last_gt = last_gt_mask_batch.detach().cpu().numpy()[0]\n",
    "        last_pr = last_pr_mask_batch.detach().cpu().numpy()[0]\n",
    "\n",
    "        threshold = 0.95\n",
    "        binary_mask = (last_pr > threshold)\n",
    "\n",
    "        ground_truth = vis_img(last_image, last_gt)\n",
    "        predicted = vis_img(last_image, binary_mask)\n",
    "        # Log\n",
    "        wandb.log({\"loss\": epoch_loss,\n",
    "                   \"val_loss\": val_loss,\n",
    "                   \"ground_truth\": wandb.Image(ground_truth),\n",
    "                   \"prediction\": wandb.Image(predicted)})\n",
    "\n",
    "        # save the best model\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), './model/unet-tune/model_best.pth')\n",
    "\n",
    "    # Return the validation loss as this is the value to be optimized\n",
    "    run.finish()\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23afbaa1-3754-4435-8dd9-f2b9521de13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-07 15:56:53,894] A new study created in memory with name: no-name-9a3003ef-62cb-4905-a4bc-b362fe307c35\n",
      "/tmp/ipykernel_1729/3584275792.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-07 15:56:54,139 - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mming686\u001b[0m (\u001b[33mdeeplearning-med\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/DL_MED/Project/wandb/run-20230607_155656-t8g9cubr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deeplearning-med/Unet-Res50-Tune/runs/t8g9cubr' target=\"_blank\">Unet-Res50-trial-0</a></strong> to <a href='https://wandb.ai/deeplearning-med/Unet-Res50-Tune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deeplearning-med/Unet-Res50-Tune' target=\"_blank\">https://wandb.ai/deeplearning-med/Unet-Res50-Tune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deeplearning-med/Unet-Res50-Tune/runs/t8g9cubr' target=\"_blank\">https://wandb.ai/deeplearning-med/Unet-Res50-Tune/runs/t8g9cubr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [02:17<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Train Loss: 87.9100975394249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:21<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1, Validation Loss: 20.88624197244644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/96 [00:03<01:11,  1.27it/s]\n",
      "[W 2023-06-07 16:00:41,606] Trial 0 failed with parameters: {'lr': 1.2742501079003229e-05, 'batch_size': 16, 'weight_decay': 1e-05, 'optimizer': 'SGD', 'loss_func': 'DiceLoss'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1729/3584275792.py\", line 77, in train_model\n",
      "    epoch_loss += loss.item()\n",
      "KeyboardInterrupt\n",
      "[W 2023-06-07 16:00:41,608] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Print out the best hyperparameters\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[8], line 77\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     75\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     76\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 77\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(train_model, n_trials=100)\n",
    "\n",
    "# Print out the best hyperparameters\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774544a9-efcc-4ed1-afad-d9e467eb25cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
